{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "982e3e3d-fcee-4425-9133-5d8586c1c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efba4bfb-686d-45cd-89a5-87e9e95c46a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c252d3e6644e569d2498047f6d75e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/sysop/.local/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:2160: FutureWarning: The class `AutoModelForVision2Seq` is deprecated and will be removed in v5.0. Please use `AutoModelForImageTextToText` instead.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face 模型\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer, AutoImageProcessor\n",
    "\n",
    "# --- 載入預訓練模型 ---\n",
    "# 1. 視覺模型：用於理解圖片內容，這裡使用 ViT 模型。\n",
    "# ViT (Vision Transformer) 能夠將圖片轉換為有意義的向量表示。\n",
    "vision_model_name = \"google/vit-base-patch16-224\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(vision_model_name)\n",
    "vision_model = AutoModel.from_pretrained(vision_model_name)\n",
    "\n",
    "# 2. 語言模型：用於理解文字內容，這裡使用 BERT 模型。\n",
    "# BERT (Bidirectional Encoder Representations from Transformers) 能將文字轉換為有意義的向量表示。\n",
    "text_model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(text_model_name)\n",
    "text_model = AutoModel.from_pretrained(text_model_name)\n",
    "\n",
    "# 3. 圖片辨識模型：用於給圖片打標籤，幫助理解圖片內容。\n",
    "# 這個模型會直接給出圖片的文字描述。\n",
    "image_to_text_pipeline = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def get_text_embeddings(text):\n",
    "    \"\"\"使用 BERT 模型將文字轉換為向量。\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = text_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "def get_image_embeddings(image_path):\n",
    "    \"\"\"\n",
    "    使用 ViT 模型和 AutoImageProcessor 將圖片轉換為向量。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. 使用 PIL 讀取圖片\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # 2. 使用 Hugging Face 處理器進行預處理\n",
    "        # 處理器會自動將圖片轉換成模型所需的格式 (這裡會得到一個字典)\n",
    "        inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "        \n",
    "        # 3. 將處理後的張量傳給模型\n",
    "        with torch.no_grad():\n",
    "            outputs = vision_model(**inputs)\n",
    "            \n",
    "        # 4. 獲取並返回特徵向量\n",
    "        # 這裡我們取平均，得到一個固定維度的向量\n",
    "        return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"處理圖片 {image_path} 時發生錯誤: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80e8f5f-e268-48e4-931d-7ebb895f6c49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "def read_presentation_content(file_path):\n",
    "    \"\"\"\n",
    "    從簡報檔案中讀取文字和圖片，並返回一個結構化的列表。\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): 簡報檔案的路徑。\n",
    "\n",
    "    Returns:\n",
    "        list: 包含每張投影片文字和圖片路徑的列表。\n",
    "    \"\"\"\n",
    "    # 檢查檔案是否存在\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"錯誤：找不到簡報檔案 '{file_path}'。\")\n",
    "        return None\n",
    "\n",
    "    # 讀取簡報檔案\n",
    "    prs = Presentation(file_path)\n",
    "    \n",
    "    # 建立一個暫存目錄來儲存圖片\n",
    "    temp_image_dir = \"temp_images\"\n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "    \n",
    "    extracted_content = []\n",
    "\n",
    "    # 逐頁遍歷簡報中的每一張投影片\n",
    "    for slide_index, slide in enumerate(prs.slides):\n",
    "        slide_text = []\n",
    "        slide_images = []\n",
    "        \n",
    "        # 遍歷投影片中的每一個形狀 (shape)，以尋找文字和圖片\n",
    "        for shape in slide.shapes:\n",
    "            # 檢查是否為文字框\n",
    "            if shape.has_text_frame:\n",
    "                text = shape.text_frame.text\n",
    "                if text:\n",
    "                    slide_text.append(text)\n",
    "            \n",
    "            # 檢查是否為圖片\n",
    "            if hasattr(shape, 'image'):\n",
    "                image_blob = shape.image.blob\n",
    "                image_filename = f\"slide_{slide_index}_shape_{len(slide_images)}.png\"\n",
    "                image_path = os.path.join(temp_image_dir, image_filename)\n",
    "                \n",
    "                # 將圖片二進制數據寫入檔案\n",
    "                with open(image_path, \"wb\") as f:\n",
    "                    f.write(image_blob)\n",
    "                \n",
    "                slide_images.append(image_path)\n",
    "        \n",
    "        # 將該投影片的內容整理成一個字典\n",
    "        content_for_slide = {\n",
    "            \"text\": \" \".join(slide_text),\n",
    "            \"images\": slide_images\n",
    "        }\n",
    "        extracted_content.append(content_for_slide)\n",
    "        \n",
    "    print(f\"成功從簡報中提取了 {len(extracted_content)} 張投影片的內容。\")\n",
    "    return extracted_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34d71a1d-aedd-4b11-be62-5056a31c38e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功從簡報中提取了 38 張投影片的內容。\n"
     ]
    }
   ],
   "source": [
    "extracted_content = read_presentation_content(\"pytorch.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62e2c569-670c-479d-94c3-640174cd63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_sort_content(extracted_content):\n",
    "    \"\"\"\n",
    "    核心邏輯：分析文字和圖片內容，並進行排序。\n",
    "    這個函數的邏輯決定了簡報的整理品質。\n",
    "    \"\"\"\n",
    "    content_with_scores = []\n",
    "    \n",
    "    # 遍歷每一張投影片的內容\n",
    "    for page_idx, page_content in enumerate(extracted_content):\n",
    "        text_content = page_content[\"text\"]\n",
    "        image_paths = page_content[\"images\"]\n",
    "        \n",
    "        # 使用文字模型計算文字向量\n",
    "        text_embedding = get_text_embeddings(text_content) if text_content else None\n",
    "        \n",
    "        # 使用圖片模型計算圖片向量\n",
    "        image_embeddings = [get_image_embeddings(path) for path in image_paths if path]\n",
    "        \n",
    "        # 使用 image-to-text 模型為圖片生成描述\n",
    "        image_descriptions = [image_to_text_pipeline(path) for path in image_paths if path]\n",
    "        \n",
    "        # (這裡只是簡化範例，你可以根據需要設計更複雜的排序邏輯)\n",
    "        # 例如：\n",
    "        # - 計算圖片描述與文字內容的相似度，將相關圖片與文字放在一起\n",
    "        # - 對所有文字內容進行聚類，將主題相近的文字放在一起\n",
    "        # - 根據內容的關鍵字 (例如 \"結論\", \"介紹\") 進行排序\n",
    "        \n",
    "        # 簡單的排序邏輯：將文字內容和圖片描述合併，並作為排序的依據\n",
    "        combined_text = text_content + \" \" + \" \".join([desc[0]['generated_text'] for desc in image_descriptions])\n",
    "        combined_embedding = get_text_embeddings(combined_text)\n",
    "        \n",
    "        # 在這裡，我們假設簡報的順序是根據內容的「主題」或「概念」排序\n",
    "        # 為了簡化，我們只將每一頁的內容及其向量存儲起來\n",
    "        if combined_embedding is not None:\n",
    "            content_with_scores.append({\n",
    "                \"page_index\": page_idx,\n",
    "                \"content\": page_content,\n",
    "                \"embedding\": combined_embedding\n",
    "            })\n",
    "\n",
    "    # (這裡應該是你的排序邏輯，例如基於 embedding 的相似度聚類)\n",
    "    # 為了簡化，我們假設我們想將內容相似的投影片排在一起\n",
    "    # 在實際應用中，你需要設計一個更複雜的排序演算法\n",
    "    sorted_content = sorted(content_with_scores, key=lambda x: torch.norm(x['embedding']))\n",
    "    \n",
    "    return [item['content'] for item in sorted_content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56360df9-929a-4c94-a75d-62f6e3b3973b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sysop/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sorted_content = analyze_and_sort_content(extracted_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41346ff6-4d1b-4714-9f66-2e42f50f69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_presentation(sorted_content, output_path=\"cleaned_presentation.pptx\"):\n",
    "    \"\"\"根據排序好的內容生成一份新的簡報。\"\"\"\n",
    "    prs = Presentation()\n",
    "    for page_content in sorted_content:\n",
    "        # 新增一張投影片\n",
    "        slide_layout = prs.slide_layouts[5]  # 使用空白投影片版型\n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        \n",
    "        # 在投影片上加入文字\n",
    "        if page_content[\"text\"]:\n",
    "            txBox = slide.shapes.add_textbox(Inches(1), Inches(1), Inches(8), Inches(2))\n",
    "            tf = txBox.text_frame\n",
    "            tf.text = page_content[\"text\"]\n",
    "        \n",
    "        # 在投影片上加入圖片\n",
    "        for i, image_path in enumerate(page_content[\"images\"]):\n",
    "            left = Inches(1) + i * Inches(2)\n",
    "            top = Inches(4)\n",
    "            slide.shapes.add_picture(image_path, left, top, height=Inches(2))\n",
    "            \n",
    "    prs.save(output_path)\n",
    "    print(f\"新的簡報已儲存至 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d81ba8f-7a97-464a-82ff-724c7084e1a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'product_a_image.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_new_presentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcleaned_presentation.pptx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mgenerate_new_presentation\u001b[0;34m(sorted_content, output_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m         left \u001b[38;5;241m=\u001b[39m Inches(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m Inches(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     18\u001b[0m         top \u001b[38;5;241m=\u001b[39m Inches(\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m         \u001b[43mslide\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshapes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_picture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mInches\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m prs\u001b[38;5;241m.\u001b[39msave(output_path)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m新的簡報已儲存至 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pptx/shapes/shapetree.py:370\u001b[0m, in \u001b[0;36m_BaseGroupShapes.add_picture\u001b[0;34m(self, image_file, left, top, width, height)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21madd_picture\u001b[39m(\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    355\u001b[0m     image_file: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m     height: Length \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    360\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Picture:\n\u001b[1;32m    361\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add picture shape displaying image in `image_file`.\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    `image_file` can be either a path to a file (a string) or a file-like object. The picture\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    aspect ratio.\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     image_part, rId \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_add_image_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     pic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_pic_from_image_part(image_part, rId, left, top, width, height)\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recalculate_extents()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pptx/parts/slide.py:50\u001b[0m, in \u001b[0;36mBaseSlidePart.get_or_add_image_part\u001b[0;34m(self, image_file)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_or_add_image_part\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_file: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m]):\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return `(image_part, rId)` pair corresponding to `image_file`.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    The returned |ImagePart| object contains the image in `image_file` and is\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    related to this slide with the key `rId`. If either the image part or\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m    relationship already exists, they are reused, otherwise they are newly created.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     image_part \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_package\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_add_image_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     rId \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelate_to(image_part, RT\u001b[38;5;241m.\u001b[39mIMAGE)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_part, rId\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pptx/package.py:38\u001b[0m, in \u001b[0;36mPackage.get_or_add_image_part\u001b[0;34m(self, image_file)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_or_add_image_part\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_file: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m]):\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    Return an |ImagePart| object containing the image in *image_file*. If\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    the image part already exists in this package, it is reused,\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    otherwise a new one is created.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_image_parts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_add_image_part\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pptx/package.py:153\u001b[0m, in \u001b[0;36m_ImageParts.get_or_add_image_part\u001b[0;34m(self, image_file)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_or_add_image_part\u001b[39m(\u001b[38;5;28mself\u001b[39m, image_file: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m IO[\u001b[38;5;28mbytes\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImagePart:\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return |ImagePart| object containing the image in `image_file`.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    `image_file` can be either a path to an image file or a file-like object\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    containing an image. If an image part containing this same image already exists,\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    that instance is returned, otherwise a new image part is created.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m     image_part \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_by_sha1(image\u001b[38;5;241m.\u001b[39msha1)\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m image_part \u001b[38;5;28;01mif\u001b[39;00m image_part \u001b[38;5;28;01melse\u001b[39;00m ImagePart\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_package, image)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pptx/parts/image.py:163\u001b[0m, in \u001b[0;36mImage.from_file\u001b[0;34m(cls, image_file)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return a new |Image| object loaded from `image_file`.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m`image_file` can be either a path (str) or a file-like object.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_file, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# treat image_file as a path\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    164\u001b[0m         blob \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    165\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(image_file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'product_a_image.png'"
     ]
    }
   ],
   "source": [
    "generate_new_presentation(sorted_content, output_path=\"cleaned_presentation.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23d67bc5-1774-44ec-baec-055a428b818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_structured_txt_report(sorted_content, output_path=\"report.txt\"):\n",
    "    \"\"\"\n",
    "    將整理好的簡報內容輸出成易於檢視的結構化 .txt 檔案。\n",
    "\n",
    "    Args:\n",
    "        sorted_content (list): 包含每張投影片文字和圖片描述的列表。\n",
    "        output_path (str): 輸出的 .txt 檔案路徑。\n",
    "    \"\"\"\n",
    "    if not sorted_content:\n",
    "        print(\"警告：沒有內容可以輸出。\")\n",
    "        return\n",
    "\n",
    "    # 假設我們有一個簡單的函式來生成圖片描述，以便範例運行\n",
    "    def get_image_description(image_path):\n",
    "        # 在實際應用中，這裡會調用 AI 模型來生成描述\n",
    "        # 例如：image_to_text_pipeline(image_path)\n",
    "        return f\"圖片描述 (來源: {os.path.basename(image_path)})\"\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"# 簡報整理報告\\n\\n\")\n",
    "        f.write(\"此報告由 AI 模型自動整理而成。\\n\")\n",
    "        f.write(\"------------------------------\\n\\n\")\n",
    "\n",
    "        # 逐頁寫入整理後的內容\n",
    "        for i, page_content in enumerate(sorted_content):\n",
    "            # 使用標題標示投影片序號\n",
    "            f.write(f\"## 第 {i+1} 張投影片\\n\")\n",
    "            f.write(\"------------------------------\\n\")\n",
    "\n",
    "            # 寫入文字內容\n",
    "            f.write(f\"### 文字內容：\\n\")\n",
    "            f.write(f\"{page_content['text']}\\n\\n\")\n",
    "\n",
    "            # 寫入圖片描述清單\n",
    "            if page_content['images']:\n",
    "                f.write(\"### 圖片重點：\\n\")\n",
    "                for image_path in page_content['images']:\n",
    "                    # 假設我們已經有圖片描述\n",
    "                    description = get_image_description(image_path)\n",
    "                    f.write(f\"- {description}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\\n\")  # 在每張投影片之間留空行，增加可讀性\n",
    "    \n",
    "    print(f\"整理後的報告已成功輸出至 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53db0eb3-bc5b-4132-aea5-c74203d7a936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整理後的報告已成功輸出至 report.txt\n"
     ]
    }
   ],
   "source": [
    "generate_structured_txt_report(sorted_content, output_path=\"report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee3b29-833f-463b-af1f-02bb6dd1b2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
